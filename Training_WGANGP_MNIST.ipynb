{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/imraunav/MNIST_GAN/blob/main/Training_WGANGP_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nqZHuIQDH31c"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision import transforms\n",
        "from torchvision.utils import save_image\n",
        "from torch.utils.data import Dataset, DataLoader, ConcatDataset\n",
        "import os\n",
        "from time import time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "IIjiyqsSzCoW"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed = 32\n",
        "torch.cuda.manual_seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "print(\"Seed set!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-8ZcnYK9uhHn",
        "outputId": "d61d1913-55f2-4639-b71e-a3b28254dca5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed set!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kxIQjPuQtmgH",
        "outputId": "a2c68e2b-c727-4e33-a415-0fbb6b593409"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose(\n",
        "    [\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5,), (0.5,)),\n",
        "        transforms.Resize((32, 32), max_size=None, antialias=True)\n",
        "    ]\n",
        ")\n",
        "train_ds = MNIST(\"./MNIST\", download=True, train=True, transform=transform)\n",
        "test_ds = MNIST(\"./MNIST\", download=True, train=False, transform=transform)\n",
        "\n",
        "mnist_ds = ConcatDataset([train_ds, test_ds])"
      ],
      "metadata": {
        "id": "7TqA0pdgILI2"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "dataloader = DataLoader(mnist_ds, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "NPl_wRIYIWj7"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient_penalty(real, fake):\n",
        "\tm = real.shape[0]\n",
        "\tepsilon = torch.rand(m, 1, 1, 1)\n",
        "\tis_cuda = torch.cuda.is_available()\n",
        "\tif is_cuda:\n",
        "\t\tepsilon = epsilon.cuda()\n",
        "\t# print(epsilon.shape, real.shape, fake.shape)\n",
        "\tinterpolated_img = epsilon * real + (1-epsilon) * fake\n",
        "\tinterpolated_out = discriminator(interpolated_img)\n",
        "\n",
        "\tgrads = torch.autograd.grad(outputs=interpolated_out, inputs=interpolated_img,\n",
        "\t\t\t\t\t\t\t   grad_outputs=torch.ones(interpolated_out.shape).cuda() if is_cuda else torch.ones(interpolated_out.shape),\n",
        "\t\t\t\t\t\t\t   create_graph=True, retain_graph=True)[0]\n",
        "\tgrads = grads.reshape([m, -1])\n",
        "\tgrad_penalty = ((grads.norm(2, dim=1) - 1) ** 2).mean()\n",
        "\treturn grad_penalty"
      ],
      "metadata": {
        "id": "k2Fdg-hXbSuH"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_dim = 100\n",
        "\n",
        "class Generator(torch.nn.Module):\n",
        "    def __init__(self, channels=1):\n",
        "        super().__init__()\n",
        "        # Filters [1024, 512, 256]\n",
        "        # Input_dim = 100\n",
        "        # Output_dim = C (number of channels)\n",
        "        self.main_module = nn.Sequential(\n",
        "            # Z latent vector 100\n",
        "            nn.ConvTranspose2d(in_channels=latent_dim, out_channels=1024, kernel_size=4, stride=1, padding=0),\n",
        "            nn.BatchNorm2d(num_features=1024),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            # State (1024x4x4)\n",
        "            nn.ConvTranspose2d(in_channels=1024, out_channels=512, kernel_size=4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(num_features=512),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            # State (512x8x8)\n",
        "            nn.ConvTranspose2d(in_channels=512, out_channels=256, kernel_size=4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(num_features=256),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            # State (256x16x16)\n",
        "            nn.ConvTranspose2d(in_channels=256, out_channels=channels, kernel_size=4, stride=2, padding=1))\n",
        "            # output of main module --> Image (Cx32x32)\n",
        "\n",
        "        self.output = nn.Tanh()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), x.size(1), 1, 1)\n",
        "        x = self.main_module(x)\n",
        "        return self.output(x)\n",
        "\n",
        "\n",
        "class Discriminator(torch.nn.Module):\n",
        "    def __init__(self, channels=1):\n",
        "        super().__init__()\n",
        "        # Filters [256, 512, 1024]\n",
        "        # Input_dim = channels (Cx64x64)\n",
        "        # Output_dim = 1\n",
        "        self.main_module = nn.Sequential(\n",
        "            # Omitting batch normalization in critic because our new penalized training objective (WGAN with gradient penalty) is no longer valid\n",
        "            # in this setting, since we penalize the norm of the critic's gradient with respect to each input independently and not the enitre batch.\n",
        "            # There is not good & fast implementation of layer normalization --> using per instance normalization nn.InstanceNorm2d()\n",
        "            # Image (Cx32x32)\n",
        "            nn.Conv2d(in_channels=channels, out_channels=256, kernel_size=4, stride=2, padding=1),\n",
        "            nn.InstanceNorm2d(256, affine=True),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            # State (256x16x16)\n",
        "            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=4, stride=2, padding=1),\n",
        "            nn.InstanceNorm2d(512, affine=True),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            # State (512x8x8)\n",
        "            nn.Conv2d(in_channels=512, out_channels=1024, kernel_size=4, stride=2, padding=1),\n",
        "            nn.InstanceNorm2d(1024, affine=True),\n",
        "            nn.LeakyReLU(0.2, inplace=True))\n",
        "            # output of main module --> State (1024x4x4)\n",
        "\n",
        "        self.output = nn.Sequential(\n",
        "            # The output of D is no longer a probability, we do not apply sigmoid at the output of D.\n",
        "            nn.Conv2d(in_channels=1024, out_channels=1, kernel_size=4, stride=1, padding=0))\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.main_module(x)\n",
        "        return self.output(x)\n",
        "\n",
        "    def feature_extraction(self, x):\n",
        "        # Use discriminator for feature extraction then flatten to vector of 16384\n",
        "        x = self.main_module(x)\n",
        "        return x.view(-1, 1024*4*4)\n",
        "\n",
        "\n",
        "# class Generator(nn.Module):\n",
        "#     def __init__(self, hidden_dim=512):\n",
        "#         super().__init__()\n",
        "#         self.net = nn.Sequential(\n",
        "#                 nn.Linear(latent_dim, hidden_dim),\n",
        "#                 nn.BatchNorm1d(hidden_dim),\n",
        "#                 nn.LeakyReLU(),\n",
        "\n",
        "#                 nn.Linear(hidden_dim, hidden_dim),\n",
        "#                 nn.BatchNorm1d(hidden_dim),\n",
        "#                 nn.LeakyReLU(),\n",
        "\n",
        "#                 nn.Linear(hidden_dim, 784),\n",
        "#         )\n",
        "#     def forward(self, noise):\n",
        "#         batch_size = noise.size(0)\n",
        "#         return self.net(noise).view(batch_size, 1, 28, 28).sigmoid() # [B, C*H*W] -> [B, C, H, W]\n",
        "\n",
        "# class Discriminator(nn.Module):\n",
        "#     def __init__(self):\n",
        "#         super().__init__()\n",
        "#         self.net = nn.Sequential(\n",
        "#                 nn.Linear(784, 256),\n",
        "#                 nn.ReLU(),\n",
        "#                 nn.Dropout(p=0.3),\n",
        "\n",
        "#                 nn.Linear(256, 256),\n",
        "#                 nn.ReLU(),\n",
        "#                 nn.Dropout(p=0.3),\n",
        "\n",
        "#                 nn.Linear(256, 1),\n",
        "#         )\n",
        "#     def forward(self, img):\n",
        "#         batch_size = img.size(0)\n",
        "#         img = img.view(batch_size, -1)  # [B, C, H, W] -> [B, C*H*W]\n",
        "#         return self.net(img)"
      ],
      "metadata": {
        "id": "S9LR3XoILRJD"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"Device: \", device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E6TaySugOTdB",
        "outputId": "2b0a8fb1-1dbe-4ca6-9b99-723010276571"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device:  cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generator = Generator().to(device)\n",
        "discriminator = Discriminator().to(device)"
      ],
      "metadata": {
        "id": "tbQLBHg3OeRt"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# noise = torch.rand((32, latent_dim), device=device)\n",
        "\n",
        "# img = generator(noise)\n",
        "# print(img.shape)\n",
        "\n",
        "# score = discriminator(img)\n",
        "# print(score.shape)"
      ],
      "metadata": {
        "id": "G2-XBw-AOI11"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dummy_latent = torch.rand((64, latent_dim), device=device)\n",
        "\n",
        "# dummy_img = generator(dummy_latent)"
      ],
      "metadata": {
        "id": "-ryXwqvp1ZlI"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dummy_img.shape"
      ],
      "metadata": {
        "id": "IuB8wGM91ZjD"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from IPython.display import Image\n",
        "# progress_path = \"drive/MyDrive/GAN_MNIST/progress\"\n",
        "# os.makedirs(progress_path, exist_ok=True)\n",
        "# save_image(dummy_img, progress_path+\"/dummy.png\", nrow=8)\n",
        "\n",
        "# Image(os.path.join(progress_path, 'dummy.png'))"
      ],
      "metadata": {
        "id": "B03_sUtm4mu6"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JK3W3tnJ1Zeo"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(generator)\n",
        "print(discriminator)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mUesBYB3PaUq",
        "outputId": "df08f90d-7bf3-447e-cd8c-ee7b2d2ca2b0"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generator(\n",
            "  (main_module): Sequential(\n",
            "    (0): ConvTranspose2d(100, 1024, kernel_size=(4, 4), stride=(1, 1))\n",
            "    (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (8): ReLU(inplace=True)\n",
            "    (9): ConvTranspose2d(256, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "  )\n",
            "  (output): Tanh()\n",
            ")\n",
            "Discriminator(\n",
            "  (main_module): Sequential(\n",
            "    (0): Conv2d(1, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
            "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (3): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (4): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
            "    (5): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (6): Conv2d(512, 1024, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (7): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
            "    (8): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "  )\n",
            "  (output): Sequential(\n",
            "    (0): Conv2d(1024, 1, kernel_size=(4, 4), stride=(1, 1))\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gen_opt = torch.optim.Adam(generator.parameters(), lr=0.0001, betas=(0.0, 0.9), weight_decay=2e-5)\n",
        "disc_opt = torch.optim.Adam(discriminator.parameters(), lr=0.0001, betas=(0.0, 0.9), weight_decay=2e-5)\n",
        "\n",
        "# adv_crit = nn.BCEWithLogitsLoss().to(device)"
      ],
      "metadata": {
        "id": "65k__JDFPpfp"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def train_gen(real_batch, real_labels):\n",
        "\n",
        "#     generator.train()\n",
        "#     discriminator.eval()\n",
        "\n",
        "#     batch_size = real_batch.size(0)\n",
        "#     z = torch.normal(0, 1, (batch_size, latent_dim), device=device)\n",
        "#     fake_batch = generator(z, real_labels)\n",
        "#     # with torch.no_grad():\n",
        "#     #     score = discriminator(fake_batch)\n",
        "#     score = discriminator(fake_batch, real_labels)\n",
        "#     targets = torch.ones_like(score, device=device) # generator target is 1 for fake\n",
        "#     loss = adv_crit(score, targets)\n",
        "\n",
        "#     gen_opt.zero_grad()\n",
        "#     loss.backward()\n",
        "#     gen_opt.step()\n",
        "\n",
        "#     return loss.item()\n",
        "\n",
        "# def train_disc(real_batch, real_labels):\n",
        "\n",
        "#     generator.eval()\n",
        "#     discriminator.train()\n",
        "\n",
        "#     batch_size = real_batch.size(0)\n",
        "#     z = torch.normal(0, 1, (batch_size, latent_dim), device=device)\n",
        "#     with torch.no_grad():\n",
        "#         fake_batch = generator(z, real_labels)\n",
        "\n",
        "#     all_batch = torch.cat([real_batch, fake_batch], dim=0)\n",
        "#     all_labels = torch.cat([real_labels, real_labels], dim=0)\n",
        "#     score = discriminator(all_batch, all_labels)\n",
        "#     targets = torch.cat(\n",
        "#         [\n",
        "#             torch.ones((batch_size, 1), device=device),\n",
        "#             torch.zeros((batch_size, 1), device=device),\n",
        "#         ]\n",
        "#     )\n",
        "\n",
        "#     loss = adv_crit(score, targets)\n",
        "\n",
        "#     disc_opt.zero_grad()\n",
        "#     loss.backward()\n",
        "#     disc_opt.step()\n",
        "\n",
        "#     return loss.item()"
      ],
      "metadata": {
        "id": "JLCeZabKR-dF"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def checkpoint(epoch, losses, CKPT_PATH, CKPT=\"checkpoint.pt\"):\n",
        "    progress_path = os.path.join(CKPT_PATH, \"progress\")\n",
        "\n",
        "    state = {\n",
        "        \"epoch\" : epoch,\n",
        "        \"generator\" : generator.state_dict(),\n",
        "        \"discriminator\" : discriminator.state_dict(),\n",
        "        \"gen_opt\" : gen_opt.state_dict(),\n",
        "        \"disc_opt\" : disc_opt.state_dict(),\n",
        "        \"losses\" : losses,\n",
        "    }\n",
        "\n",
        "    os.makedirs(CKPT_PATH, exist_ok=True)\n",
        "    torch.save(state, os.path.join(CKPT_PATH, CKPT))\n",
        "\n",
        "    generator.eval()\n",
        "    gen_batch = generator(sample_latent)\n",
        "\n",
        "    os.makedirs(progress_path, exist_ok=True)\n",
        "    save_image(gen_batch, os.path.join(progress_path, f\"epoch_{epoch+1}.png\"))\n",
        "\n",
        "    print(f\"! Checkpoint saved at {epoch+1}.\")"
      ],
      "metadata": {
        "id": "XcXbaD6NqkTA"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_checkpoint(CKPT_PATH, CKPT=\"checkpoint.pt\"):\n",
        "    state = torch.load(os.path.join(CKPT_PATH, CKPT))\n",
        "    generator.load_state_dict(state[\"generator\"])\n",
        "    discriminator.load_state_dict(state[\"discriminator\"])\n",
        "\n",
        "    gen_opt.load_state_dict(state[\"gen_opt\"])\n",
        "    disc_opt.load_state_dict(state[\"disc_opt\"])\n",
        "\n",
        "    return state[\"epoch\"], state[\"losses\"]"
      ],
      "metadata": {
        "id": "VwN5-rnAsIOD"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_EPOCH = 500\n",
        "CKPT_PATH = \"drive/MyDrive/WGANGP_MNIST\"\n",
        "CKPT_EVERY = 10\n",
        "\n",
        "Z_DIM = latent_dim\n",
        "CHANNELS = 1\n",
        "N_CRITIC = 5\n",
        "GRADIENT_PENALTY = 10\n",
        "LOAD_MODEL = False\n",
        "\n",
        "sample_latent = torch.normal(0, 1, (64, latent_dim), device=device)\n",
        "# sample_labels = torch.randint(0, 10, (64,), device=device)\n",
        "# print(f\"Checkpoint labels to sample: {sample_labels}\")\n",
        "\n",
        "losses = {\n",
        "    \"gen_loss\" : [],\n",
        "    \"disc_loss\" : [],\n",
        "}\n",
        "\n",
        "start = 0\n",
        "# Load checkpoint if found\n",
        "if os.path.exists(CKPT_PATH+\"/checkpoint.pt\"):\n",
        "    print(\"Checkpoint found\")\n",
        "    print('Loading checkpoint...')\n",
        "    start, losses = load_checkpoint(CKPT_PATH)\n",
        "    checkpoint(start, losses, CKPT_PATH)\n",
        "\n",
        "tic = time()\n",
        "total_iter = 0\n",
        "max_iter = len(dataloader)\n",
        "\n",
        "for epoch in range(start, MAX_EPOCH):\n",
        "    generator.train()\n",
        "    discriminator.train()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}\", end=\" \")\n",
        "    running_losses = {\n",
        "        \"gen_loss\" : [],\n",
        "        \"disc_loss\" : [],\n",
        "    }\n",
        "\n",
        "    for real_batch, labels in tqdm(dataloader):\n",
        "        total_iter += 1\n",
        "\n",
        "        x_real = real_batch.to(device)\n",
        "\n",
        "        z_fake = torch.randn(x_real.size(0), latent_dim, device=device)\n",
        "        x_fake = generator(z_fake)\n",
        "\n",
        "        fake_out = discriminator(x_fake.detach())\n",
        "        real_out = discriminator(x_real.detach())\n",
        "        # print(x_fake.shape, fake_out.shape, real_out.shape)\n",
        "        x_out = torch.cat([real_out, fake_out])\n",
        "        d_loss = -(real_out.mean() - fake_out.mean()) + gradient_penalty(x_real, x_fake) * GRADIENT_PENALTY + (x_out ** 2).mean() ** 0.0001\n",
        "\n",
        "        disc_opt.zero_grad()\n",
        "        d_loss.backward()\n",
        "        disc_opt.step()\n",
        "\n",
        "        running_losses[\"disc_loss\"].append(d_loss.item())\n",
        "        if total_iter % N_CRITIC == 0:\n",
        "            z_fake = torch.randn(batch_size, latent_dim, device=device)\n",
        "            x_fake = generator(z_fake)\n",
        "\n",
        "            fake_out = discriminator(x_fake)\n",
        "            g_loss = - fake_out.mean()\n",
        "\n",
        "            gen_opt.zero_grad()\n",
        "            g_loss.backward()\n",
        "            gen_opt.step()\n",
        "            running_losses[\"gen_loss\"].append(g_loss.item())\n",
        "\n",
        "    for loss_name in ['gen_loss', \"disc_loss\"]:\n",
        "        epoch_loss = running_losses[loss_name]\n",
        "        losses[loss_name].append(sum(epoch_loss)/len(epoch_loss))\n",
        "\n",
        "    print(f\"| G_loss : {losses['gen_loss'][-1]:.4f}, D_loss : {losses['disc_loss'][-1]:.4f}\")\n",
        "\n",
        "    if (epoch+1) % CKPT_EVERY == 0:\n",
        "        checkpoint(epoch, losses, CKPT_PATH)\n",
        "        # pass\n",
        "toc = time()\n",
        "checkpoint(epoch, losses, CKPT_PATH)\n",
        "print(\"Training done!\")\n",
        "print(f\"Time taken to train: {(toc-tic)/60:.3f} mins\")"
      ],
      "metadata": {
        "id": "myszQSCqQM6S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b37b2e0-9d69-4a21-d262-031be790107c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint labels to sample: tensor([4, 0, 9, 9, 4, 3, 9, 5, 8, 2, 2, 1, 4, 8, 6, 9, 9, 7, 4, 4, 6, 9, 6, 9,\n",
            "        8, 3, 6, 1, 9, 3, 6, 6, 6, 6, 3, 1, 5, 7, 4, 2, 7, 9, 1, 7, 0, 5, 7, 5,\n",
            "        5, 6, 5, 4, 6, 0, 3, 1, 6, 7, 1, 5, 6, 9, 2, 0], device='cuda:0')\n",
            "Epoch 1 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 26%|██▌       | 142/547 [01:31<04:39,  1.45it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "plt.plot(losses[\"gen_loss\"])\n",
        "plt.plot(losses[\"disc_loss\"])\n",
        "\n",
        "plt.legend([\"Generator\", \"Discriminator\"])\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "pb4cxTiOzJue"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "veh41LITf1xF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}